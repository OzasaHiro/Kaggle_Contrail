{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install /kaggle/input/segmentation-models-wheels/timm-0.6.12-py3-none-any.whl\n!pip install /kaggle/input/segmentation-models-wheels/efficientnet_pytorch-0.7.1-py3-none-any.whl\n!pip install /kaggle/input/segmentation-models-wheels/pretrainedmodels-0.7.4-py3-none-any.whl\n!pip install /kaggle/input/segmentation-models-wheels/segmentation_models_pytorch-0.3.2-py3-none-any.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic modules\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport os\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport random\n\n# Visualization\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom IPython import display\n\n# pytorch modules\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import BCELoss, Sigmoid\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau \nfrom torchvision.transforms import Normalize\nfrom torch.multiprocessing import Pool\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom collections import OrderedDict\nfrom torch.optim import lr_scheduler\n\nfrom timm.scheduler import CosineLRScheduler\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch_xla\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = \"/kaggle/input/google-research-identify-contrails-reduce-global-warming/\"\ntrain_path = os.path.join(base_dir,\"train\")\ntest_path = os.path.join(base_dir,\"test\")\nval_path = os.path.join(base_dir,\"validation\")\n\ntrain_ids = os.listdir(train_path)\n#train_ids = np.loadtxt(\"/kaggle/input/train-ids-existcontrail/train_ids_ExistContrail.csv\", delimiter=\",\", dtype = \"unicode\")\n#train_ids = train_ids.tolist()\n\ntest_ids = os.listdir(test_path)\nval_ids = os.listdir(val_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ash_transform(x, time_frame:int=4):\n    _T11_BOUNDS = (243, 303)\n    _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n    _TDIFF_BOUNDS = (-4, 2)\n    if time_frame is not None:\n        x = x[:,time_frame,:,:]\n    def normalize_range(data, bounds):\n        \"\"\"Maps data to the range [0, 1].\"\"\"\n        return (data - bounds[0]) / (bounds[1] - bounds[0])\n\n    r = normalize_range(x[2] - x[1], _TDIFF_BOUNDS)\n    g = normalize_range(x[1] - x[0], _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(x[1], _T11_BOUNDS)\n    \n    return np.clip(np.stack([r, g, b], axis=-3), 0, 1) # (T,3,H,W) or (3,H,W)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_horizontal_flip(video):\n    horizontal = random.random()\n    if horizontal < 0.5:\n        return video[..., ::-1], horizontal\n    return video, horizontal\n\ndef random_vertical_flip(video):\n    vertical = random.random()\n    if vertical < 0.5:\n        return video[..., ::-1, :], vertical\n    return video, vertical\n\ndef random_mask(img, mask_size=10, musk_num=20):\n    i = 0\n    for i in range(musk_num):\n        if random.random() < 0.5:\n            h, w = img.shape[-2:]\n            top = random.randint(0, h - mask_size)\n            left = random.randint(0, w - mask_size)\n            img[..., top:top+mask_size, left:left+mask_size] = 0\n            i += 1\n    return img\n\ndef augment_video(video):\n    #video = random_vertical_flip(video)  #正解データも反転させないとダメでは？\n    #print(video.shape)\n    video = np.stack([random_mask(frame) for frame in video.transpose(1, 0, 2, 3)])\n\n    return video.transpose(1, 0, 2, 3)\n\n\n# Test with dummy data\n#video = np.random.rand(3, 10, 224, 224)\n#augmented_video = augment_video(video)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrailDataset(Dataset):\n    def __init__(self, ids, base_dir, bands=None, transforms:list=[], test_mode:bool=False, aug=False):\n        self.ids = ids\n        self.base_dir = base_dir\n        self.transforms = transforms\n        self.bands = bands\n        self.permute = (2,0,1)\n        self.test_mode = test_mode\n        self.aug = aug\n        \n    def __getitem__(self, index):\n        record_id = self.ids[index]\n        \n        if self.bands is None:\n            band_list = [f'band_{band:02d}.npy' for band in range(8,17)]\n        else :\n            band_list = [f'band_{int(band):02d}.npy' for band in self.bands]\n        \n        x = list()\n        for band in band_list:\n            x_path = os.path.join(self.base_dir, record_id, band)\n            x.append(np.load(x_path).transpose(self.permute))\n\n        x = np.stack(x,axis=1) ## X.shape = (Time_frame,channel,H,W)\n        \n        x = x.transpose((1,0,2,3)) ## PLUS ## X.shape = (channel, Time_frame ,H,W)\n        \n        #print(x.shape)\n        \n        if self.aug:\n            #print(x.shape)\n            #x,hor = random_horizontal_flip(x)\n            #x,ver = random_vertical_flip(x)\n            #x = augment_video(x)\n            x = random_mask(x)\n        \n        \n        for transformation in self.transforms:\n            x = transformation(x)\n            \n\n        \n        x = torch.from_numpy(x.astype(np.float32))\n        \n        if self.test_mode:\n            return x\n        else:\n            y_path = os.path.join(self.base_dir, record_id,'human_pixel_masks.npy')\n            y = np.load(y_path).transpose(self.permute)\n            #if self.aug:\n               # if hor < 0.5:\n                 #   y = y[:, :, ::-1]\n               # if ver < 0.5:\n                #    y = y[:, ::-1, :]\n            \n            y = torch.from_numpy(y.astype(np.float32))\n\n            return x, y\n\n    def __len__(self):\n        return len(self.ids)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.cpu_count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Datasets \ndataset_params = {\n    \"bands\" : [11,14,15], \n    \"transforms\" : [ash_transform]\n}\ntrain_dataset = ContrailDataset(train_ids, train_path, **dataset_params, aug=True)\ntest_dataset = ContrailDataset(test_ids, test_path, test_mode=True, **dataset_params)\nval_dataset = ContrailDataset(val_ids, val_path, **dataset_params)\n\n# DalaLoaders\ndataloader_params = {\n    \"batch_size\" : 16,\n    \"shuffle\" : True,\n    \"num_workers\": 20,\n    \"drop_last\": True\n#     \"pin_memory\": True\n\n}\ntrain_loader = DataLoader(train_dataset, **dataloader_params)\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=2)\nval_loader = DataLoader(val_dataset, **dataloader_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_contrail(x, y, time_frame = 4):\n    '''\n    x = false color img of shape (8, 3, H, W)\n    y = contrail mask of shape (1, H, W)\n    time_frame = int, default = 4\n    '''\n    if x.ndim == 4:\n        x = x[time_frame]\n    \n    plt.figure(figsize=(18, 6))\n    ax = plt.subplot(1, 3, 1)\n    ax.imshow(x.permute(1,2,0))\n    ax.set_title('False color image')\n\n    ax = plt.subplot(1, 3, 2)\n    ax.imshow(y.permute(1,2,0), interpolation='none')\n    ax.set_title('Ground truth contrail mask')\n\n    ax = plt.subplot(1, 3, 3)\n    ax.imshow(x.permute(1,2,0))\n    ax.imshow(y.permute(1,2,0), cmap='Reds', alpha=.4, interpolation='none')\n    ax.set_title('Contrail mask on false color image');\n\n    plt.show()\n\ndef plot_contrail_comparision(x, y_true, y_pred, time_frame = 4):\n    '''\n    x = false color img of shape (3, H, W) or (8, 3, H, W)\n    y_true = target contrail mask of shape (1, H, W)\n    y_pred = predicted contrail mask of shape (1, H, W)\n    time_frame = int, default = 4\n    '''\n    if x.ndim == 4:\n        x = x[time_frame]\n    \n    plt.figure(figsize=(18, 6))\n    ax = plt.subplot(1, 5, 1)\n    ax.imshow(x.permute(1,2,0))\n    ax.set_title('False color image(x)')\n    ax.axis('off')\n    \n    ax = plt.subplot(1, 5, 2)\n    ax.imshow(y_true.permute(1,2,0), interpolation='none')\n    ax.set_title('True contrail mask(y_true)')\n    ax.axis('off')\n    \n    ax = plt.subplot(1, 5, 3)\n    ax.imshow(x.permute(1,2,0))\n    ax.imshow(y_true.permute(1,2,0), cmap='Reds', alpha=.4, interpolation='none')\n    ax.set_title('y_true mask on x')\n    ax.axis('off')\n    \n    ax = plt.subplot(1, 5, 4)\n    ax.imshow(y_pred.permute(1,2,0), interpolation='none')\n    ax.set_title('Pred contrail mask(y_pred)')\n    ax.axis('off')\n\n    ax = plt.subplot(1, 5, 5)\n    ax.imshow(x.permute(1,2,0))\n    ax.imshow(y_pred.permute(1,2,0), cmap='Reds', alpha=.4, interpolation='none')\n    ax.set_title('y_pred mask on x')\n    ax.axis('off')\n    \n    plt.show()\n\ndef animate_contrail(x):\n    '''\n    x = false color img of shape (8, 3, H, W)\n    '''\n    if x.ndim !=4:\n        print(f\"Incorrect input dimensions, Expected 4 recievied {x.ndim}.\")\n        return\n    # Animation\n    fig = plt.figure(figsize=(4, 4))\n    im = plt.imshow(x[0].permute(1,2,0))\n    def draw(i):\n        im.set_array(x[i].permute(1,2,0))\n        return [im]\n    anim = animation.FuncAnimation(\n        fig, draw, frames=x.shape[0], interval=100, blit=True\n    )\n    plt.close()\n    return display.HTML(anim.to_jshtml())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" x, y = train_dataset[train_ids.index('1704010292581573769')]\n plot_contrail(x, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dice Coefficient\ndef dice_coeff(mask1, mask2):\n    intersect = torch.sum(mask1 * mask2)\n    m1sum = torch.sum(mask1)\n    m2sum = torch.sum(mask2)\n    dice = (2 * intersect ) / (m1sum + m2sum)\n    return dice.item()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callbacks\nclass History:\n    def __init__(self, print_prefix, save_to_disk=True):\n        self.train_batch_history = []\n        self.val_batch_histroy = []\n        self.train_epoch_history = []\n        self.val_epoch_history = []\n        self.running_train_batch_history = []\n        self.running_val_batch_history = []\n        self.print_prefix = print_prefix\n        self.save_to_disk = save_to_disk\n        if save_to_disk:\n            self.save_path = os.path.join(os.getcwd(),\"saved_states\",self.print_prefix)\n            if not os.path.exists(self.save_path):\n                os.makedirs(self.save_path)\n    def on_train_batch_end(self, data):\n        self.running_train_batch_history.append(data)\n        \n    def on_val_batch_end(self, data):\n        self.running_val_batch_history.append(data)\n        \n    def on_epoch_end(self):\n        self.train_epoch_history.append(np.mean(self.running_train_batch_history))\n        self.train_batch_history.extend(self.running_train_batch_history)\n        self.running_train_batch_history=[]\n        self.val_epoch_history.append(np.mean(self.running_val_batch_history))\n        self.val_batch_histroy.extend(self.running_val_batch_history)\n        self.running_val_batch_history=[]\n        print(f\"{self.print_prefix}: Train = {self.train_epoch_history[-1]:.6f} \\\n        | Val = {self.val_epoch_history[-1]:.6f}\")\n    \n    def on_end(self):\n        if self.save_to_disk:\n            #dt = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n            np.save(os.path.join(self.save_path,\"train_batch.npy\"),self.train_batch_history)\n            np.save(os.path.join(self.save_path,\"val_batch.npy\"),self.val_batch_histroy)\n            np.save(os.path.join(self.save_path,\"train_epoch.npy\"),self.train_epoch_history)\n            np.save(os.path.join(self.save_path,\"val_epoch.npy\"),self.val_epoch_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BestStateTracker:\n    def __init__(self, model, optim, trigger:History, save_to_disk:bool = False):\n        self.trigger = trigger\n        self.model = model\n        self.optim = optim\n        self.optim_state = None\n        self.model_state = None\n        self.best_loss = np.inf\n        self.save_to_disk = save_to_disk\n        if save_to_disk:\n            self.save_path = os.path.join(os.getcwd(),\"saved_states\")\n            if not os.path.exists(self.save_path):\n                os.mkdir(self.save_path)\n                \n    def on_epoch_end(self):\n        if self.trigger.val_epoch_history[-1] < self.best_loss:\n            self.model_state = self.model.state_dict()\n            self.optim_state = self.optim.state_dict()\n            \n    def on_end(self):\n        if self.save_to_disk:\n            #dt = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n            xm.save(self.model_state,os.path.join(self.save_path,f\"model_state_end.pt\"))\n            xm.save(self.optim_state,os.path.join(self.save_path,f\"optim_state_end.pt\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ASPP(nn.Module):\n    def __init__(self, in_channels, out_channels, dilations):\n        super(ASPP, self).__init__()\n        self.aspp_blocks = nn.ModuleList()\n        for dilation in dilations:\n            self.aspp_blocks.append(\n                nn.Sequential(\n                    nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation, dilation=dilation, bias=False),\n                    nn.BatchNorm2d(out_channels),\n                    nn.ReLU(inplace=True))\n                )\n\n    def forward(self, x):\n        return sum(block(x) for block in self.aspp_blocks)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n\n    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n        super(UNet, self).__init__()\n\n        features = init_features\n        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.bottleneck = ASPP(features * 8, features * 16, dilations=[1, 6, 12, 18])\n\n        self.upconv4 = nn.ConvTranspose2d(\n            features * 16, features * 8, kernel_size=2, stride=2\n        )\n        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n        self.upconv3 = nn.ConvTranspose2d(\n            features * 8, features * 4, kernel_size=2, stride=2\n        )\n        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n        self.upconv2 = nn.ConvTranspose2d(\n            features * 4, features * 2, kernel_size=2, stride=2\n        )\n        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n        self.upconv1 = nn.ConvTranspose2d(\n            features * 2, features, kernel_size=2, stride=2\n        )\n        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n\n        self.conv = nn.Conv2d(\n            in_channels=features, out_channels=out_channels, kernel_size=1\n        )\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool1(enc1))\n        enc3 = self.encoder3(self.pool2(enc2))\n        enc4 = self.encoder4(self.pool3(enc3))\n\n        bottleneck = self.bottleneck(self.pool4(enc4))\n\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.decoder4(dec4)\n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n        return torch.sigmoid(self.conv(dec1))\n\n    @staticmethod\n    def _block(in_channels, features, name):\n        return nn.Sequential(\n            OrderedDict(\n                [\n                    (\n                        name + \"conv1\",\n                        nn.Conv2d(\n                            in_channels=in_channels,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu1\", nn.ReLU(inplace=True)),\n                    (\n                        name + \"conv2\",\n                        nn.Conv2d(\n                            in_channels=features,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu2\", nn.ReLU(inplace=True)),\n                ]\n            )\n        )\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = xm.xla_device()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet().to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''ENCODER = 'timm-efficientnet-b4' #'resnet101''timm-efficientnet-b4'\nENCODER_WEIGHTS = 'noisy-student' #'imagenet''noisy-student'\n\nACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n\n# create segmentation model with pretrained encoder\nmodel = smp.DeepLabV3Plus(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=1, \n    activation=ACTIVATION,\n).to(device)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Focal_MultiLabel_Loss(nn.Module):\n    def __init__(self, gamma):\n      super(Focal_MultiLabel_Loss, self).__init__()\n      self.gamma = gamma\n      self.bceloss = nn.BCELoss(reduction='none')\n\n    def forward(self, outputs, targets): \n      bce = self.bceloss(outputs, targets)\n      bce_exp = torch.exp(-bce)\n      focal_loss = (1-bce_exp)**self.gamma * bce\n      return focal_loss.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 1e-2 #2e-3\nEPOCHS = 35\n\nFLAGS={}\nFLAGS['num_cores'] = 8\nFLAGS['start_epoch'] = 0\nFLAGS['num_epochs'] = EPOCHS\nFLAGS['num_workers'] = 12\nFLAGS['log_steps'] = 100\nFLAGS['seed'] = 1234\nFLAGS['max_lr'] = LR\nFLAGS['min_lr'] = 0.00004\nFLAGS['warmup_steps'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(params=model.parameters(), lr=LR)\n#loss_fn = BCELoss()\nloss_fn = Focal_MultiLabel_Loss(gamma=2) \n\n#scheduler = ReduceLROnPlateau(optimizer)\nscheduler = CosineLRScheduler(optimizer, \n                              t_initial=EPOCHS, \n                              lr_min=FLAGS['min_lr'], \n                              warmup_t=FLAGS['warmup_steps'],\n                              warmup_lr_init=5e-6,\n                              warmup_prefix=True)\n\nloss_tracker = History(print_prefix=\"Loss\")\ndice_tracker = History(print_prefix=\"Dice\")\nsave_state = BestStateTracker(model,optimizer,loss_tracker,save_to_disk=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WRAPPED_MODEL = xmp.MpModelWrapper(model)\n\n\ndef _map_fn(index, flags):\n  pbar = tqdm(range(flags['start_epoch'], flags['num_epochs']))\n  loss_best = 1.0\n  torch.manual_seed(flags['seed'])\n\n  device = xm.xla_device()\n  model = WRAPPED_MODEL.to(device)\n  \n  train_sampler = torch.utils.data.distributed.DistributedSampler(\n    train_dataset,\n    num_replicas=xm.xrt_world_size(),\n    rank=xm.get_ordinal(),\n    shuffle=True)\n  \n  train_loader = torch.utils.data.DataLoader(\n    dataset = train_dataset,\n    batch_size = 16,\n    sampler=train_sampler,\n    num_workers=flags['num_workers'],\n    drop_last=True)\n  \n  val_sampler = torch.utils.data.distributed.DistributedSampler(\n    val_dataset,\n    num_replicas=xm.xrt_world_size(),\n    rank=xm.get_ordinal(),\n    shuffle=False)\n\n  val_loader = torch.utils.data.DataLoader(\n    dataset = val_dataset,\n    batch_size = 16,\n    sampler=val_sampler,\n    num_workers=flags['num_workers'],\n    drop_last=False)\n\n  for epoch in range(flags['start_epoch'], flags['num_epochs']):\n    current_lr = optimizer.param_groups[0]['lr']\n    xm.master_print(f\"EPOCH: {epoch+1}/{flags['num_epochs']}, Learning rate: {current_lr}\")\n    para_train_loader = pl.ParallelLoader(train_loader, [device])\n    model.train()\n    \n    for idx, (data, target) in enumerate(para_train_loader.per_device_loader(device)):\n      y_pred = model(data)\n      loss = loss_fn(y_pred, target)\n      optimizer.zero_grad()\n      loss.backward()\n      xm.optimizer_step(optimizer)\n      \n      if idx % flags['log_steps'] == 0:\n        xm.master_print(f'Train Batch: {idx+1}/{len(train_loader)} | Loss: {loss.item():.6f}')\n        \n      loss_tracker.on_train_batch_end(loss.item())\n      dice_tracker.on_train_batch_end(dice_coeff(y_pred>0.5, target))\n      #pbar.set_description(f\"Train Batch: {idx+1}/{len(train_loader)}\\\n      #| Loss: {loss.item():.6f}\")\n\n    plot_contrail_comparision(data[0].cpu().detach(),\n                           target[0].cpu().detach(),\n                           y_pred[0].cpu().detach()>0.5)\n      \n    model.eval()\n    para_val_loader = pl.ParallelLoader(val_loader, [device])\n    \n    with torch.no_grad():\n        for idx, (data, target) in enumerate(para_val_loader.per_device_loader(device)):\n            y_pred = model(data)\n            loss = loss_fn(y_pred, target)\n            loss_tracker.on_val_batch_end(loss.item())\n            dice_tracker.on_val_batch_end(dice_coeff(y_pred>0.5, target))\n            #pbar.set_description(f\"Val Batch:   {idx+1}/{len(val_loader)}\\\n            #| Loss: {loss.item():.6f}\")\n            if idx % flags['log_steps'] == 0:\n                xm.master_print(f'Val Batch: {idx+1}/{len(val_loader)} | Loss: {loss.item():.6f}')\n                \n        plot_contrail_comparision(data[0].cpu().detach(),\n                        target[0].cpu().detach(),\n                        y_pred[0].cpu().detach()>0.5)\n    \n                \n    #xm.save(model.state_dict(), flags['save_path'])    \n    scheduler.step(epoch)\n    loss_tracker.on_epoch_end()\n    dice_tracker.on_epoch_end()\n    save_state.on_epoch_end()\n\n  save_state.on_end()\n  loss_tracker.on_end()\n  dice_tracker.on_end()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xmp.spawn(_map_fn, args=(FLAGS,), nprocs=1, start_method='fork')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}